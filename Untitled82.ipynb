{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5418c937-0f3e-4683-a072-0c2f6669f94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading datasets...\n",
      "[INFO] Train shape: (14999, 9)\n",
      "[INFO] Test shape : (8764, 8)\n",
      "[INFO] Saving processed data to HDF5...\n",
      "[WARN] No labels found for Engagement, skipping.\n",
      "[WARN] No labels found for Mood, skipping.\n",
      "[WARN] No labels found for Recall, skipping.\n",
      "[INFO] Generating JSON report...\n",
      "[INFO] Writing YAML metadata...\n",
      "[INFO] Pipeline finished successfully ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import joblib\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# -------- CONFIG --------\n",
    "BASE_DIR = r\"C:\\Users\\NXTWAVE\\Downloads\\Ad Insight\"\n",
    "TRAIN_CSV = os.path.join(BASE_DIR, \"archive\", \"train.csv\")\n",
    "TEST_CSV  = os.path.join(BASE_DIR, \"archive\", \"test.csv\")\n",
    "\n",
    "OUT_H5    = os.path.join(BASE_DIR, \"processed_ads.h5\")\n",
    "OUT_ENG   = os.path.join(BASE_DIR, \"engagement_model.pkl\")\n",
    "OUT_MOOD  = os.path.join(BASE_DIR, \"mood_model.pkl\")\n",
    "OUT_REC   = os.path.join(BASE_DIR, \"recall_model.pkl\")\n",
    "OUT_JSON  = os.path.join(BASE_DIR, \"ads_report.json\")\n",
    "OUT_YAML  = os.path.join(BASE_DIR, \"build_metadata.yaml\")\n",
    "\n",
    "\n",
    "# -------- LOAD DATA --------\n",
    "print(\"[INFO] Loading datasets...\")\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "print(\"[INFO] Train shape:\", train_df.shape)\n",
    "print(\"[INFO] Test shape :\", test_df.shape)\n",
    "\n",
    "\n",
    "# -------- BASIC PREPROCESS --------\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Handle categorical columns (encode)\n",
    "    cat_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "    for c in cat_cols:\n",
    "        df[c] = df[c].fillna(\"UNK\")\n",
    "        le = LabelEncoder()\n",
    "        df[c] = le.fit_transform(df[c])\n",
    "\n",
    "    # Fill NaN numeric values\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = preprocess(train_df)\n",
    "test_df = preprocess(test_df)\n",
    "\n",
    "# -------- SAVE PROCESSED TO H5 --------\n",
    "print(\"[INFO] Saving processed data to HDF5...\")\n",
    "with h5py.File(OUT_H5, \"w\") as h5:\n",
    "    h5.create_dataset(\"train\", data=train_df.values)\n",
    "    h5.create_dataset(\"test\", data=test_df.values)\n",
    "    h5.attrs[\"train_columns\"] = json.dumps(list(train_df.columns))\n",
    "\n",
    "\n",
    "# -------- SPLIT FEATURES & TARGETS --------\n",
    "# Assume dataset has engagement, mood, recall columns as labels\n",
    "target_cols = [\"engagement\", \"mood\", \"recall\"]\n",
    "feature_cols = [c for c in train_df.columns if c not in target_cols]\n",
    "\n",
    "X = train_df[feature_cols].values\n",
    "y_eng = train_df[\"engagement\"].values if \"engagement\" in train_df else None\n",
    "y_mood = train_df[\"mood\"].values if \"mood\" in train_df else None\n",
    "y_rec = train_df[\"recall\"].values if \"recall\" in train_df else None\n",
    "\n",
    "X_train, X_val, y_eng_train, y_eng_val = train_test_split(X, y_eng, test_size=0.2, random_state=42) if y_eng is not None else (None, None, None, None)\n",
    "_, _, y_mood_train, y_mood_val = train_test_split(X, y_mood, test_size=0.2, random_state=42) if y_mood is not None else (None, None, None, None)\n",
    "_, _, y_rec_train, y_rec_val = train_test_split(X, y_rec, test_size=0.2, random_state=42) if y_rec is not None else (None, None, None, None)\n",
    "\n",
    "\n",
    "# -------- TRAIN MODELS --------\n",
    "def train_model(Xtr, ytr, Xval, yval, out_path, name):\n",
    "    if ytr is None:\n",
    "        print(f\"[WARN] No labels found for {name}, skipping.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"[INFO] Training {name} model...\")\n",
    "    clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "    clf.fit(Xtr, ytr)\n",
    "\n",
    "    preds = clf.predict(Xval)\n",
    "    acc = accuracy_score(yval, preds)\n",
    "    print(f\"[RESULT] {name} Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(yval, preds))\n",
    "\n",
    "    joblib.dump(clf, out_path)\n",
    "    return acc\n",
    "\n",
    "\n",
    "acc_eng = train_model(X_train, y_eng_train, X_val, y_eng_val, OUT_ENG, \"Engagement\")\n",
    "acc_mood = train_model(X_train, y_mood_train, X_val, y_mood_val, OUT_MOOD, \"Mood\")\n",
    "acc_rec = train_model(X_train, y_rec_train, X_val, y_rec_val, OUT_REC, \"Recall\")\n",
    "\n",
    "\n",
    "# -------- GENERATE REPORT --------\n",
    "print(\"[INFO] Generating JSON report...\")\n",
    "report = {\n",
    "    \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"metrics\": {\n",
    "        \"engagement_acc\": float(acc_eng) if acc_eng is not None else None,\n",
    "        \"mood_acc\": float(acc_mood) if acc_mood is not None else None,\n",
    "        \"recall_acc\": float(acc_rec) if acc_rec is not None else None,\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"train_shape\": train_df.shape,\n",
    "        \"test_shape\": test_df.shape,\n",
    "        \"features\": feature_cols,\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(OUT_JSON, \"w\") as f:\n",
    "    json.dump(report, f, indent=4)\n",
    "\n",
    "\n",
    "# -------- SAVE BUILD METADATA --------\n",
    "print(\"[INFO] Writing YAML metadata...\")\n",
    "metadata = {\n",
    "    \"build\": {\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"models\": {\n",
    "            \"engagement_model\": OUT_ENG,\n",
    "            \"mood_model\": OUT_MOOD,\n",
    "            \"recall_model\": OUT_REC\n",
    "        },\n",
    "        \"artifacts\": {\n",
    "            \"processed_data\": OUT_H5,\n",
    "            \"report\": OUT_JSON\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(OUT_YAML, \"w\") as f:\n",
    "    yaml.dump(metadata, f)\n",
    "\n",
    "print(\"[INFO] Pipeline finished successfully ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2227a17-c44e-4cb5-ac51-e8b9579b0cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
